//
//  ViewController.swift
//  CarolCamera
//
//  Created by larryhou on 29/11/2015.
//  Copyright Â© 2015 larryhou. All rights reserved.
//

import UIKit
import AVFoundation
import MediaPlayer
import Photos

class CaptureViewController: UIViewController, AVCaptureFileOutputRecordingDelegate
{
    var CONTEXT_LENS_LENGTH:Int = 0
    var CONTEXT_ISO:Int = 0
    var CONTEXT_EXPOSURE_DURATION:Int = 0
    var CONTEXT_OUTPUT_VOLUME:Int = 0
    var CONTEXT_MOVIE_RECORDING:Int = 0
    var CONTEXT_SESSION_RUNNING:Int = 0
    var CONTEXT_LIGHT_BOOST:Int = 0
    var CONTEXT_ADJUSTING_FOCUS:Int = 0
    
    @IBOutlet var previewView: LivePreivewView!
    @IBOutlet var flashView:UIView!
    
    @IBOutlet weak var recordingView: UIView!
    @IBOutlet weak var recordingMeter: UILabel!
    @IBOutlet weak var recordingIndicator: UIImageView!
    @IBOutlet weak var isoMeter:UILabel!
    @IBOutlet weak var focusIndicator: UIImageView!
    
    private var session:AVCaptureSession!
    private var sessionQueue:dispatch_queue_t!
    
    private var camera:AVCaptureDevice!
    
    private var photoOutput:AVCaptureStillImageOutput!
    private var movieOutput:AVCaptureMovieFileOutput!
    
    private var backgroundRecordingID:UIBackgroundTaskIdentifier!
    
    private var originVolume:Float = 1.0
    private var restoring = false
    
    private var timestamp:NSDate!
    private var timer:NSTimer!
    
    private var changeVolume:Float->Void = {volume in}
    
    dynamic
    var recording = false
    
    class func deviceWithMediaType(mediaType:String, position:AVCaptureDevicePosition)->AVCaptureDevice
    {
        let devices = AVCaptureDevice.devicesWithMediaType(mediaType) as! [AVCaptureDevice]
        var target = devices.first
        
        for item in devices
        {
            if item.position == position
            {
                target = item
                break
            }
        }
        
        return target!
        
    }
    
    func restoreVolume()
    {
        if originVolume != AVAudioSession.sharedInstance().outputVolume
        {
            restoring = true
            changeVolume(originVolume)
        }
    }
    
    override func viewDidLoad()
    {
        super.viewDidLoad()
        
        view.backgroundColor = UIColor.blackColor()
        
        focusIndicator.hidden = true
        isoMeter.hidden = true
        
        recordingView.backgroundColor = UIColor(red: 0, green: 0, blue: 0, alpha: 0.5)
        recordingView.alpha = 0.0
        
        let volumeView = MPVolumeView(frame: CGRect(x: -100, y: 0, width: 10, height: 0))
        volumeView.sizeToFit()
        
        view.addSubview(volumeView)
        
        for view in volumeView.subviews
        {
            if view.dynamicType.description() == "MPVolumeSlider"
            {
                let slider = view as! UISlider
                changeVolume =
                { value in
                    dispatch_async(dispatch_get_main_queue())
                    {
                        slider.setValue(value, animated: true)
                        slider.sendActionsForControlEvents(.TouchUpInside)
                    }
                }
                break
            }
        }
        
        addObserver(self, forKeyPath: "recording", options: .New, context: &CONTEXT_MOVIE_RECORDING)
        
        AVAudioSession.sharedInstance().addObserver(self, forKeyPath: "outputVolume", options: [.New, .Old], context: &CONTEXT_OUTPUT_VOLUME)
    }
    
    override func viewDidAppear(animated: Bool)
    {
        super.viewDidAppear(animated)
        
        originVolume = AVAudioSession.sharedInstance().outputVolume
        
        session = AVCaptureSession()
        session.addObserver(self, forKeyPath: "running", options: .New, context: &CONTEXT_SESSION_RUNNING)
        session.sessionPreset = AVCaptureSessionPresetPhoto
        
        previewView.session = session
        
        sessionQueue = dispatch_queue_create("CaptureSessionQueue", DISPATCH_QUEUE_SERIAL)
        
        var authorized = true
        let status = AVCaptureDevice.authorizationStatusForMediaType(AVMediaTypeVideo)
        switch status
        {
            case .NotDetermined, .Denied:
                dispatch_suspend(self.sessionQueue)
                AVCaptureDevice.requestAccessForMediaType(AVMediaTypeVideo)
                { (granted:Bool) in
                    
                    if !granted
                    {
                        authorized = false
                    }
                    
                    dispatch_resume(self.sessionQueue)
                }
            default:
                print(status, status.rawValue)
        }
        
        dispatch_async(self.sessionQueue)
        {
            if !authorized
            {
                return
            }
            
            self.backgroundRecordingID = UIBackgroundTaskInvalid
            
            //MARK: camera input
            let cameraDevice = CaptureViewController.deviceWithMediaType(AVMediaTypeVideo, position: .Back)
            var cameraInput:AVCaptureDeviceInput! = nil
            
            do
            {
                cameraInput = try AVCaptureDeviceInput(device: cameraDevice)
            }
            catch
            {
                self.showAlertMessage(String(error))
                return
            }
            
            self.camera = cameraDevice
            self.session.beginConfiguration()
            
            if self.session.canAddInput(cameraInput)
            {
                self.session.addInput(cameraInput)
                
                dispatch_async(dispatch_get_main_queue())
                {
                    var vedioOrientation = AVCaptureVideoOrientation.Portrait
                    
                    let deviceOrientation = UIApplication.sharedApplication().statusBarOrientation
                    if deviceOrientation != .Unknown
                    {
                        vedioOrientation = AVCaptureVideoOrientation(rawValue: deviceOrientation.rawValue)!
                    }
                    
                    (self.previewView.layer as! AVCaptureVideoPreviewLayer).connection.videoOrientation = vedioOrientation
                }
            }
            else
            {
                self.showAlertMessage("Could not add camera input")
                return
            }
            
            //MARK: microphone input
            let audio = AVCaptureDevice.defaultDeviceWithMediaType(AVMediaTypeAudio)
            var audioInput:AVCaptureDeviceInput! = nil
            do
            {
                audioInput = try AVCaptureDeviceInput(device: audio)
            }
            catch {}
            
            if audioInput != nil && self.session.canAddInput(audioInput)
            {
                self.session.addInput(audioInput)
            }
            else
            {
                self.showAlertMessage("Could not add microphone input")
            }
            
            //MARK: photo output
            let photoOutput = AVCaptureStillImageOutput()
            if self.session.canAddOutput(photoOutput)
            {
                self.session.addOutput(photoOutput)
                self.photoOutput = photoOutput
                photoOutput.outputSettings = [AVVideoCodecKey:AVVideoCodecJPEG]
                photoOutput.highResolutionStillImageOutputEnabled = true
            }
            else
            {
                self.showAlertMessage("Could not add photo output")
            }
            
            //MARK: movie output
            let movieOutput = AVCaptureMovieFileOutput()
            if self.session.canAddOutput(movieOutput)
            {
                self.session.addOutput(movieOutput)
                self.movieOutput = movieOutput
                
                let movieConnnection = movieOutput.connectionWithMediaType(AVMediaTypeVideo)
                if  movieConnnection.supportsVideoStabilization
                {
                    movieConnnection.preferredVideoStabilizationMode = .Auto
                }
            }
            else
            {
                self.showAlertMessage("Could not add movie output")
            }
            
            self.session.commitConfiguration()
            
            self.camera.addObserver(self, forKeyPath: "lensPosition", options: .New, context: &self.CONTEXT_LENS_LENGTH)
            self.camera.addObserver(self, forKeyPath: "ISO", options: .New, context: &self.CONTEXT_ISO)
            self.camera.addObserver(self, forKeyPath: "exposureDuration", options: .New, context: &self.CONTEXT_EXPOSURE_DURATION)
            self.camera.addObserver(self, forKeyPath: "lowLightBoostEnabled", options: .New, context: &self.CONTEXT_LIGHT_BOOST)
            self.camera.addObserver(self, forKeyPath: "adjustingFocus", options: .New, context: &self.CONTEXT_ADJUSTING_FOCUS)
            self.session.startRunning()
        }
    }
    
    func setupCamera(device:AVCaptureDevice)
    {
        do
        {
            try device.lockForConfiguration()
        }
        catch
        {
            return
        }
        
        if device.smoothAutoFocusSupported
        {
            device.smoothAutoFocusEnabled = true
        }
        
        if device.lowLightBoostSupported
        {
            device.automaticallyEnablesLowLightBoostWhenAvailable = true
        }
        
        device.unlockForConfiguration()
        
        focusWithMode(.ContinuousAutoFocus, exposureMode: .ContinuousAutoExposure, pointOfInterest: CGPoint(x: 0.5, y: 0.5))
    }
    
    @IBAction func screenTapped(sender: UITapGestureRecognizer)
    {
        print("tap")
        
        var point = sender.locationInView(sender.view)
        point = (previewView.layer as! AVCaptureVideoPreviewLayer).captureDevicePointOfInterestForPoint(point)
        focusWithMode(.ContinuousAutoFocus, exposureMode: .ContinuousAutoExposure, pointOfInterest: point)
    }
    
    func focusWithMode(focusMode:AVCaptureFocusMode, exposureMode:AVCaptureExposureMode, pointOfInterest:CGPoint)
    {
        let camera = self.camera
        dispatch_async(self.sessionQueue)
        {
            do
            {
                try camera.lockForConfiguration()
            }
            catch
            {
                return
            }
            
            if camera.focusPointOfInterestSupported
            {
                camera.focusPointOfInterest = pointOfInterest
            }
            
            if camera.isFocusModeSupported(focusMode)
            {
                camera.focusMode = focusMode
            }
            
            if camera.exposurePointOfInterestSupported
            {
                camera.exposurePointOfInterest = pointOfInterest
            }
            
            if camera.isExposureModeSupported(exposureMode)
            {
                camera.exposureMode = exposureMode
            }
            
            camera.subjectAreaChangeMonitoringEnabled = true
            camera.unlockForConfiguration()
        }
    }
    
    var snapIndex = 0
    override func observeValueForKeyPath(keyPath: String?, ofObject object: AnyObject?, change: [String : AnyObject]?, context: UnsafeMutablePointer<Void>)
    {
        if context == &CONTEXT_LENS_LENGTH
        {
//            print("lensPosition", camera.lensPosition)
        }
        else
        if context == &CONTEXT_EXPOSURE_DURATION
        {
//            print("exposureDuration", camera.exposureDuration)
        }
        else
        if context == &CONTEXT_ISO
        {
            isoMeter.text = String(format: "ISO:%04d", Int(camera.ISO))
        }
        else
        if context == &CONTEXT_OUTPUT_VOLUME
        {
            let newVolume = change?[NSKeyValueChangeNewKey] as! Float
            let oldVolume = change?[NSKeyValueChangeOldKey] as! Float
            if abs(newVolume - oldVolume) == 0.5 || !session.running
            {
                return
            }
            
            if restoring
            {
                restoring = false
                return
            }
            
            ++snapIndex
            print("snap", String(format: "%03d %@ %.3f %.3f", snapIndex, newVolume > oldVolume ? "+" : "-", newVolume, oldVolume))
            
            if newVolume > oldVolume
            {
                snapCamera()
            }
            else
            {
                recording = !recording
            }
            
            checkVolumeButton()
        }
        else
        if context == &CONTEXT_MOVIE_RECORDING
        {
            toggleRecording()
        }
        else
        if context == &CONTEXT_SESSION_RUNNING
        {
            print("running", session.running)
            
            if session.running
            {
                setupCamera(camera)
                checkVolumeButton()
            }
        }
        else
        if context == &CONTEXT_LIGHT_BOOST
        {
            print("lowLightBoostEnabled", camera.lowLightBoostEnabled)
        }
        else
        if context == &CONTEXT_ADJUSTING_FOCUS
        {
            focusIndicator.hidden = !camera.adjustingFocus
            if camera.adjustingFocus
            {
                focusIndex = 0
                NSTimer.scheduledTimerWithTimeInterval(0.15, target:self, selector: "twinkleFocusBox:", userInfo: nil, repeats: true)
            }
        }
    }
    
    var focusIndex = 0
    func twinkleFocusBox(timer:NSTimer)
    {
        if !camera.adjustingFocus
        {
            timer.invalidate()
            return
        }
        
        focusIndex++
        
        let alpha:CGFloat
        if focusIndex % 2 == 1
        {
            alpha = 1.0
        }
        else
        {
            alpha = 0.5
        }
        
        focusIndicator.layer.removeAllAnimations()
        UIView.animateWithDuration(0.1)
        {
            self.focusIndicator.alpha = alpha
        }
    }
    
    func updateRecordingMeter(interval:NSTimeInterval)
    {
        let time = Int(interval)
        
        let sec = time % 60
        let min = (time / 60) % 60
        let hur = (time / 60) / 60
        
        recordingMeter.text = String(format: "%02d:%02d:%02d", hur, min, sec)
    }
    
    func timerUpdate(timer:NSTimer)
    {
        updateRecordingMeter(timer.fireDate.timeIntervalSinceDate(timestamp))
        recordingIndicator.hidden = !recordingIndicator.hidden
    }
    
    func toggleRecording()
    {
        dispatch_async(sessionQueue)
        {
            if !self.movieOutput.recording
            {
                print("recording", true)
                self.session.sessionPreset = AVCaptureSessionPresetHigh
                
                if UIDevice.currentDevice().multitaskingSupported
                {
                    self.backgroundRecordingID = UIApplication.sharedApplication().beginBackgroundTaskWithExpirationHandler(nil)
                }
                
                let movieConnection = self.movieOutput.connectionWithMediaType(AVMediaTypeVideo)
                movieConnection.videoOrientation = (self.view.layer as! AVCaptureVideoPreviewLayer).connection.videoOrientation
                
                let movieFileName = NSString(string: NSProcessInfo.processInfo().globallyUniqueString).stringByAppendingPathExtension("mov")!
                let movieFilePath = NSString(string: NSTemporaryDirectory()).stringByAppendingPathComponent(movieFileName)
                
                self.movieOutput.startRecordingToOutputFileURL(NSURL.fileURLWithPath(movieFilePath), recordingDelegate: self)
            }
            else
            {
                print("recording", false)
                self.movieOutput.stopRecording()
            }
        }
    }
    
    func twenkleScreen()
    {
        flashView.layer.removeAllAnimations()
        flashView.hidden = false
        flashView.alpha = 1.0
        
        let animations = {
            self.flashView.alpha = 0.0
        }
        
        UIView.animateWithDuration(0.2, animations:animations)
        { success in
            self.flashView.hidden = true
        }
    }
    
    //MARK: take still image
    func snapCamera()
    {
        twenkleScreen()
        dispatch_async(self.sessionQueue)
        {
            let imageConnection = self.photoOutput.connectionWithMediaType(AVMediaTypeVideo)
            imageConnection.videoOrientation = (self.previewView.layer as! AVCaptureVideoPreviewLayer).connection.videoOrientation
            
            self.photoOutput.captureStillImageAsynchronouslyFromConnection(imageConnection)
            { (buffer:CMSampleBuffer!, error:NSError!) in
                if error != nil
                {
                    self.showAlertMessage(String(format: "Error capture still image %@", error))
                }
                else
                if buffer != nil
                {
                    let data = AVCaptureStillImageOutput.jpegStillImageNSDataRepresentation(buffer)
                    PHPhotoLibrary.requestAuthorization
                    { (status:PHAuthorizationStatus) in
                        if status == PHAuthorizationStatus.Authorized
                        {
                            let photoWriting = {
                                PHAssetCreationRequest.creationRequestForAsset().addResourceWithType(.Photo, data: data, options: nil)
                            }
                            
                            PHPhotoLibrary.sharedPhotoLibrary().performChanges(photoWriting)
                            { (success, error:NSError?) in
                                if !success
                                {
                                    self.showAlertMessage("Error occured while saving image to photo library")
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    
    //MARK: check volume button
    func checkVolumeButton()
    {
        do
        {
            try AVAudioSession.sharedInstance().setActive(true, withOptions: .NotifyOthersOnDeactivation)
        }
        catch {}
        
        let volume = AVAudioSession.sharedInstance().outputVolume
        if volume == 1.0 || volume == 0.0
        {
            changeVolume(0.5)
        }
    }
    
    //MARK: record delegate
    func captureOutput(captureOutput: AVCaptureFileOutput!, didStartRecordingToOutputFileAtURL fileURL: NSURL!, fromConnections connections: [AnyObject]!)
    {
        print(__FUNCTION__)
        
        dispatch_async(dispatch_get_main_queue())
        {
            self.recordingView.layer.removeAllAnimations()
            self.recordingView.alpha = 0.5
            
            UIView.animateWithDuration(0.2)
            {
                self.recordingView.alpha = 1.0
            }
            
            self.timestamp = NSDate()
            
            self.updateRecordingMeter(0)
            self.timer = NSTimer.scheduledTimerWithTimeInterval(0.5, target: self, selector: "timerUpdate:", userInfo: nil, repeats: true)
        }
    }
    
    func captureOutput(captureOutput: AVCaptureFileOutput!, didFinishRecordingToOutputFileAtURL outputFileURL: NSURL!, fromConnections connections: [AnyObject]!, error: NSError!)
    {
        print(__FUNCTION__)
        
        timer.invalidate()
        dispatch_async(dispatch_get_main_queue())
        {
            self.recordingView.layer.removeAllAnimations()
            UIView.animateWithDuration(0.5)
            {
                self.recordingView.alpha = 0.0
            }
        }
        
        session.sessionPreset = AVCaptureSessionPresetPhoto
        checkVolumeButton()
        
        //MARK: write movie file
        let backgroundTaskID = self.backgroundRecordingID
        self.backgroundRecordingID = UIBackgroundTaskInvalid
        
        let cleanup = {
            do
            {
                try NSFileManager.defaultManager().removeItemAtURL(outputFileURL)
            }
            catch {}
            
            if backgroundTaskID != UIBackgroundTaskInvalid
            {
                UIApplication.sharedApplication().endBackgroundTask(backgroundTaskID)
            }
        }
        
        var success = true
        if error != nil
        {
           success = error.userInfo[AVErrorRecordingSuccessfullyFinishedKey] as! Bool
        }
        
        if success
        {
            PHPhotoLibrary.requestAuthorization
            { (status:PHAuthorizationStatus) in
                if status == PHAuthorizationStatus.Authorized
                {
                    let movieWriting = {
                        let options = PHAssetResourceCreationOptions()
                        options.shouldMoveFile = true
                        
                        let request = PHAssetCreationRequest.creationRequestForAsset()
                        request.addResourceWithType(.Video, fileURL: outputFileURL, options: options)
                    }
                    
                    PHPhotoLibrary.sharedPhotoLibrary().performChanges(movieWriting)
                    { (success:Bool, error:NSError?) in
                        if !success
                        {
                            self.showAlertMessage(String(format: "Could not save movie to photo library: %@", error!))
                        }
                        
                        cleanup()
                    }
                }
                else
                {
                    cleanup()
                }
            }
        }
        else
        {
            cleanup()
        }
    }
    
    //MARK: alert
    func showAlertMessage(message:String)
    {
        let alert = UIAlertController(title: "ERROR", message: message, preferredStyle: .Alert)
        alert.addAction(UIAlertAction(title: "I've got it!", style: .Default, handler: nil))
        dispatch_async(dispatch_get_main_queue())
        {
            self.presentViewController(alert, animated: true, completion: nil)
        }
    }
    
    //MARK: orientation
    override func viewWillTransitionToSize(size: CGSize, withTransitionCoordinator coordinator: UIViewControllerTransitionCoordinator)
    {
        super.viewWillTransitionToSize(size, withTransitionCoordinator: coordinator)
        
        let deviceOrientation = UIDevice.currentDevice().orientation
        if deviceOrientation.isPortrait || deviceOrientation.isLandscape
        {
            (previewView.layer as! AVCaptureVideoPreviewLayer).connection.videoOrientation = AVCaptureVideoOrientation(rawValue: deviceOrientation.rawValue)!
        }
    }
    
    override func prefersStatusBarHidden() -> Bool
    {
        return true
    }

    override func didReceiveMemoryWarning()
    {
        super.didReceiveMemoryWarning()
    }
}

